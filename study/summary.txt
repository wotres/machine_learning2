
배치 경사 하강법 : 전체 데이터를 다 집어 넣은 뒤에 한번에 가중치 갱신
확률적 경사 하강법 : 데이터 마다 가중치를 갱신 -> 수렴 속도 더욱 빠름
미니 배치 학습 : 한 배치를 32개의 샘플 정도로 정하면 32개 마다 확률적보다 배치가 일어나서 속도가 더욱 빠르다.

###############################################################

오즈비(p/1-p) 에서 특정 이벤트가 발생할 활귤을 구하고 로그 함수를 붙여 log(p/1-p) : 로짓함수를 정의한뒤 
이를 뒤집어 실제 구하고 싶은 확률 P = 1/(1+e^-z) 를 이용한 것이 시그모이드 함수 -> 로지스틱 회귀 분석
이떄 -z 는 가중치와 샘플 특성의 선형 조합으로 이루어진 최종 입력 ∑wx

###############################################################
최대화 하려는 가능도를 로그 붙이면 로그 가능도 함수라고 함
-> 가능도가 매우작을 떄 일어나는 수치상으 ㅣ언더플로를 미연에 방지하고 계소의 곱을 합으로 바꿀 수 있음

###############################################################
분산은 모델을 여러 번 훈련했을 떄 특정 샘플에 대한 예측의 일관성을 측정
편향은 예측이 정확한 값에서 얼마나 벗어났는가를 측정 -> 즉, 구조적 에러

규제는 과도한 파라미터 값을 제한하기 위해 추가적인 정보(편향)를 주입하는 개념

###############################################################
모수모델 : 퍼셉트론, 로지스틱 회귀, 선형 SVM
비모수 모델 : 결정 트리/랜덤 포레스트와 커널 SVM


